\chapter{Related Work}
\label{chap-two}
There has been considerable amount of work in the area of micro blog mining. The different techniques and results are discussed in this chapter.

\section{Twitter Classification}
Twitter classification is used as the first step in many different twitter mining techniques. It is used as an intelligent data cleaning method to remove the unnecessary tweets from the initial twitter dataset. \citet{Sakaki:2010:EST:1772690.1772777} use classification as an intelligent filter in their technique of detecting the occurrence, time and location of earthquakes and typhoons by mining tweets. They provide a multi step process to obtain this information. Their first step is to classify the tweets into two classes -tweets pertaining to real earthquakes and tweets not pertaining to real earthquakes. They use a Support Vector Machine based classifier with different types of features like,

\begin{description}
\item[A.] Statistical Features (Number of words, Position of query word)
\item[B.] Keyword Features (Word vector of the Tweet)
\item[C.] Word Context Features (Words before and after the query word)
\end{description}

Their classifier does really well at detecting earthquake events when they use only statistical features on the features. It has a F-value of 73.69\%. Its F-value is lower when they used other features 53.85\% and 57.14\% for B and C respectively. This is further emphasized by the work of \citet{Sriram:2010:STC:1835449.1835643}. They describe a technique for organizing tweets into different top level classes using a Naive Bayes classifier. The goal of their work is to classify sets of tweets into generic classes, such as News, Opinions, Deals, Events, or Private Messages. The best performing classifier relies on eight features, one nominal and the remaining binary, collectively called 8F:

\begin{enumerate}
\item author (nominal)
\item presence of shortening of words and slang terms,
\item time/event phrases,
\item opinion words,
\item emphasis words,
\item currency and percentage signs,
\item @username at the beginning of the tweet, and
\item @username within the tweet.
\end{enumerate}

The overall accuracy of 8F is around 95\%. Because the model uses author information, however, it will tend to be tuned to each user's tweeting habits. This is the main drawback of this approach; as a trained model cannot be easily applied to tweets from new users. The authors write, "The author feature is found to be very discriminative in our dataset." They also test their work against a Bag-of-Words (BOW) feature set, and find that 8F improves performance by 32.1\% over BOW. So even they concluded that statistically computed features seem to perform significantly better than Bag of Words. Performance of the combined 7F+BOW (7F is 8F with the author feature removed) falls between 8F and BOW. 

\section{Twitter Summarization}
A substantial amount of work has been done in exploring different techniques to summarize tweets. The word summary has been used as a common term for any information that is concise and extracted from a larger body of tweets. It takes different structures based on the context. The techniques of extracting summary too differ significantly based on the context and application. \citet{DBLP:conf/icwsm/ChakrabartiP11} have described different approaches to summarize an American football game. They aim to recognize all the sub events in a game like touchdowns, field goals etc using the tweets pertaining to the game. They have evaluated three different algorithms for this task. The first algorithm is called SUMMALLTEXT based on calculating euclidean distance between word vectors of every pair of tweets and choosing the one with the least distance from all other tweets and highest distance from already chosen tweets. This process is repeated for a specified number of times. This approach has many drawbacks, It gives too much importance to the one major sub event, It cannot recognize two separate events of the same type like two touchdowns at different times. They take this as the baseline for evaluating their other algorithms. To differentiate the events better temporally they use an important parameter in summarizing a football game. They divide the tweets into different time slots and apply the SUMMALLTEXT. This results in temporally segregated set of sub events. This is called SUMMTIMEINT. It suffers mostly with the same problems as SUMMALLTEXT. Finally they describe a variant of Hidden Markov Model(HMM) which recognizes the changes in the language model over time better than the SUMMALLTEXT and SUMMTIMEINT. They call it SUMMHMM. They train the model for American football game before running the evaluation. The models generated are very specific to the type of event hence the model needs to be trained for every new type of event. The model mainly depends on bursts in tweet volume and changes in language model over time. This makes the model usable only for events which are like sports, where there are defined important moments which correlate to bursts in tweet volume. The evaluation shows that on an average recall is just 0.5 when top 30 tweets are extracted after the SUMMHMM computation. This shows that recognizing sub events is really a hard problem even when you consider trained models.

\citet{Nichols:2012:SSE:2166966.2166999} try to address the shortcomings of a trained model to recognize sub events and summarize them. To demonstrate their technique for summarizing sporting events they have used a running example of soccer. Apart from recognizing the sub events they aim to provide a set of sentences as summary of a soccer game. They use the burst in tweet volume information to detect  events like a goal, yellow card and penalty shoot etc. Each burst in tweet is considered a sub event they detect the exact burst of tweets and the collect all the tweets from start of the burst to the end of the tweet burst. This is considered as a cluster. They remove the noise and choose the top ‘n’ sentences from each cluster ranking them based on the phrase graph approach discussed in \citet{Sharifi:2010:SMA:1857999.1858099}. This model is unsupervised unlike other approaches used for summarizing tweets of an event. However this model relies on the fact that each burst of tweets is one event. This may not hold true if two important events occurred in quick succession. Quick succession of events in common in some sports like American football. \citet{DBLP:conf/icwsm/ChakrabartiP11} have reported that in their dataset of American football games 45\% of the interception-plays were followed by field-goals or touchdown-plays. They also cite this as a reason for some performance drop in there SUMMHMM approach.  \citet{Nichols:2012:SSE:2166966.2166999} have evaluated their model only on a soccer game which has relatively less number of events and generally the events for a soccer game are well spaced out in time compared to other games like American football or basketball. However their results show a recall ranging from 0.6 to 0.9 and a precision of around 0.9 for the soccer games they have evaluated. This is a promising result considering the difficulty of the problem.

Searching twitter for important real time information is an important application of twitter. Query phrase based summarization techniques have been explored for providing good search results. \citet{DBLP:conf/icwsm/OConnorKA10} have a built a system to summarize the search results for a given term from twitter. A user can enter a keyword, the output will be a clustered sets of tweets identifying the different subtopics about the keyword. They use a series of steps to identify these subtopics. They can be either unigrams, bigrams or trigrams. In the first step they tokenize and filter the words. In the next step they calculate the importance of each token using probability of occurrence in the result subset and general tweet corpus. Then they merge similar topics using jaccard coefficient of similarity between the n-grams. They remove near duplicate tweets by looking at trigrams. This approach is interesting and good to extract the sub topics from a given topic. However it relies heavily on the tokenizer and probability of occurrence of words. This can lead to non important but frequently used words being chosen as the topics in case of users' tweets. It is common for a particular user to use similar words over and over again which do not represent a sub topic. Example words like ‘president’, ’POTUS’ which stands for President of The United States etc are used extensively in President Barack Obama’s twitter feed. Using this algorithm they would get recognized as the main topics of clusters thus resulting in substandard results. 

A very well known approach to summarizing tweets based on query word is the technique described by \citet{Sharifi:2010:SMA:1857999.1858099}. They describe an algorithm called the Phrase Reinforcement(PR) algorithm which can be used summarize a set of tweets. They have described the algorithm as a method to filter search results for a query term on twitter. The PR algorithm begins by creating a phrase graph of all the tweets obtained with the query term as the root node. Then each phrase which occurs in the context of the root node is augmented to the phrase graph. Then the graph is weighted based on a scheme which weighs heavily on repetition of words. Then the sentence with the highest weight is taken out first and so on to generate a partial summary.  This technique could be used to summarize cluster of tweets which belong to a related event. However this technique is not suitable for summarizing cluster formed by tweets of a user because, we  found that same sets of words are not used adjacent to the topic phrase when we look at tweets of a single user. For example for a  topic like ‘health care’ which is seen as a topic in President Obama's tweets shows that the context is sometimes women's health and sometimes it is related to health insurance.

